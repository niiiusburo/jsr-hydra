services:
  jsr-mt5:
    build:
      context: ./infra/mt5
      dockerfile: Dockerfile
    container_name: jsr-mt5
    ports:
      - "127.0.0.1:5900:5900"
      - "127.0.0.1:6901:6901"
      - "18812:18812"
    volumes:
      - jsr-mt5data:/config
    environment:
      - CUSTOM_USER=${MT5_VNC_USER:-admin}
      - PASSWORD=${MT5_VNC_PASSWORD:-admin}
      - MT5_LOGIN=${MT5_LOGIN:-0}
      - MT5_PASSWORD=${MT5_PASSWORD:-}
      - MT5_SERVER=${MT5_SERVER:-}
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:18812/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 180s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

  jsr-postgres:
    image: postgres:16-alpine
    container_name: jsr-postgres
    environment:
      POSTGRES_DB: jsr_hydra
      POSTGRES_USER: ${DB_USER:-postgres}
      POSTGRES_PASSWORD: ${DB_PASS:-postgres}
    volumes:
      - jsr-pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

  jsr-redis:
    image: redis:7-alpine
    container_name: jsr-redis
    volumes:
      - jsr-redisdata:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

  jsr-backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: jsr-backend
    ports:
      - "8000:8000"
    environment:
      - APP_ENV=${APP_ENV:-development}
      - DATABASE_URL=postgresql+asyncpg://${DB_USER:-postgres}:${DB_PASS:-postgres}@jsr-postgres:5432/jsr_hydra
      - REDIS_URL=redis://jsr-redis:6379/0
      - MT5_HOST=jsr-mt5
      - MT5_RPYC_PORT=18812
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1/chat/completions}
      - ZAI_API_KEY=${ZAI_API_KEY:-}
      - ZAI_MODEL=${ZAI_MODEL:-glm-4.6}
      - ZAI_BASE_URL=${ZAI_BASE_URL:-https://api.z.ai/api/paas/v4/chat/completions}
      - BRAIN_LLM_PROVIDER=${BRAIN_LLM_PROVIDER:-openai}
    env_file:
      - .env
    volumes:
      - ./version.json:/app/version.json:ro
    depends_on:
      jsr-postgres:
        condition: service_healthy
      jsr-redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import urllib.request; urllib.request.urlopen(\"http://localhost:8000/api/system/health\")' || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

  jsr-engine:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: jsr-engine
    command: python -m app.engine.engine_runner
    environment:
      - APP_ENV=${APP_ENV:-development}
      - DATABASE_URL=postgresql+asyncpg://${DB_USER:-postgres}:${DB_PASS:-postgres}@jsr-postgres:5432/jsr_hydra
      - REDIS_URL=redis://jsr-redis:6379/0
      - MT5_HOST=jsr-mt5
      - MT5_RPYC_PORT=18812
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1/chat/completions}
      - ZAI_API_KEY=${ZAI_API_KEY:-}
      - ZAI_MODEL=${ZAI_MODEL:-glm-4.6}
      - ZAI_BASE_URL=${ZAI_BASE_URL:-https://api.z.ai/api/paas/v4/chat/completions}
      - BRAIN_LLM_PROVIDER=${BRAIN_LLM_PROVIDER:-openai}
    env_file:
      - .env
    depends_on:
      jsr-postgres:
        condition: service_healthy
      jsr-redis:
        condition: service_healthy
      jsr-backend:
        condition: service_healthy
      jsr-mt5:
        condition: service_healthy
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 2G
    volumes:
      - jsr-mlmodels:/app/models
      - ./version.json:/app/version.json:ro
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

  # NOT YET IMPLEMENTED (Phase 3) â€” RL model retrainer.
  # This service is gated behind the "retrainer" profile so it will NOT start
  # with a normal `docker compose up`. To run it explicitly:
  #   docker compose --profile retrainer up jsr-retrainer
  # The retrainer will exit gracefully if no RL state / model files exist yet.
  jsr-retrainer:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: jsr-retrainer
    command: python -m app.engine.retrainer
    profiles: ["retrainer"]
    environment:
      - DATABASE_URL=postgresql+asyncpg://${DB_USER:-postgres}:${DB_PASS:-postgres}@jsr-postgres:5432/jsr_hydra
      - REDIS_URL=redis://jsr-redis:6379/0
    env_file:
      - .env
    depends_on:
      jsr-backend:
        condition: service_started
    restart: on-failure  # Don't restart on clean exit (exit 0 = no data to retrain)
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 256m
    volumes:
      - jsr-mlmodels:/app/models
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

  jsr-frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: jsr-frontend
    ports:
      - "3000:3000"
    depends_on:
      - jsr-backend
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

  jsr-caddy:
    image: caddy:2
    container_name: jsr-caddy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infra/caddy/Caddyfile:/etc/caddy/Caddyfile
      - jsr-caddydata:/data
    depends_on:
      - jsr-backend
      - jsr-frontend
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"
    networks:
      - jsr-network

volumes:
  jsr-pgdata:
  jsr-mt5data:
  jsr-mlmodels:
  jsr-caddydata:
  jsr-redisdata:

networks:
  jsr-network:
    driver: bridge
